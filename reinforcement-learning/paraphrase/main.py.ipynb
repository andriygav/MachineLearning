{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1aabee",
   "metadata": {},
   "source": [
    "# Paraphrase Generation with Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa5b05",
   "metadata": {},
   "source": [
    "Обзор работы по использованию обучения с подкреплением для задачи машинного перевода. Статья по [ссылке](https://www.aclweb.org/anthology/D18-1421.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24733f4d",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4825bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77be99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убирем рандом\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24178802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b707ee",
   "metadata": {},
   "source": [
    "## Базовый пример обучения генерации парафраза\n",
    "[На основе кода по генерации перевода.](https://pytorch.org/tutorials/beginner/translation_transformer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769c41d",
   "metadata": {},
   "source": [
    "### Скачиваем данные для парафраза на инглийском.\n",
    "[Статья 2021 года. ParaSCI: A Large Scientific Paraphrase Dataset for Longer Paraphrase Generation.](https://github.com/dqxiu/ParaSCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b25fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://raw.githubusercontent.com/dqxiu/ParaSCI/master/Data/ParaSCI-ACL/'\n",
    "train_urls = ('train/train.src', 'train/train.tgt')\n",
    "val_urls = ('val/val.src', 'val/val.tgt')\n",
    "test_urls = ('test/test.src', 'test/test.tgt')\n",
    "\n",
    "train_filepaths = [download_from_url(url_base + url) for url in train_urls]\n",
    "val_filepaths = [download_from_url(url_base + url) for url in val_urls]\n",
    "test_filepaths = [download_from_url(url_base + url) for url in test_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f585a3",
   "metadata": {},
   "source": [
    "### Строим словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5d88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def build_vocab(filepaths, tokenizer):\n",
    "    counter = Counter()\n",
    "    for filepath in filepaths:\n",
    "        with io.open(filepath, encoding=\"utf8\") as f:\n",
    "            for string_ in f:\n",
    "                counter.update(tokenizer(string_))\n",
    "    return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "vocab = build_vocab(train_filepaths, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7e53d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14821"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf936ada",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6287d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(filepaths):\n",
    "    raw_src_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
    "    raw_tgt_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
    "    data = []\n",
    "    for (raw_src, raw_tgt) in zip(raw_src_iter, raw_tgt_iter):\n",
    "        src_tensor_ = torch.tensor(\n",
    "            [vocab[token] for token in tokenizer(raw_src.rstrip(\"\\n\"))],\n",
    "            dtype=torch.long)\n",
    "        tgt_tensor_ = torch.tensor(\n",
    "            [vocab[token] for token in tokenizer(raw_tgt.rstrip(\"\\n\"))],\n",
    "            dtype=torch.long)\n",
    "        data.append((src_tensor_, tgt_tensor_))\n",
    "    return data\n",
    "\n",
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d854cb3",
   "metadata": {},
   "source": [
    "### Финальные датасеты для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c91a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "PAD_IDX = vocab['<pad>']\n",
    "BOS_IDX = vocab['<bos>']\n",
    "EOS_IDX = vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c05061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for (src_item, tgt_item) in data_batch:\n",
    "        src_batch.append(torch.cat([torch.tensor([BOS_IDX]), src_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        tgt_batch.append(torch.cat([torch.tensor([BOS_IDX]), tgt_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668b2c1",
   "metadata": {},
   "source": [
    "### Класс модели SEQ2SEQ transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c5ebf",
   "metadata": {},
   "source": [
    "#### Определение самой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447d3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "    \n",
    "# Делаем, так чтобы в обучении не было заглядывания на дальнешие слова\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcac06",
   "metadata": {},
   "source": [
    "#### Определения декодирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27c0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol, num_samples=1):\n",
    "    src = src.to(DEVICE)\n",
    "    src = torch.cat([src]*num_samples, dim=1)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    \n",
    "    ys = torch.ones(1, num_samples).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(DEVICE).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.detach()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        next_word.view(1, -1)], dim=0)\n",
    "    return ys.transpose(0,1)\n",
    "\n",
    "def sampling_decode(model, src, src_mask, max_len, start_symbol, num_samples=1):\n",
    "    src = src.to(DEVICE)\n",
    "    src = torch.cat([src]*num_samples, dim=1)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    \n",
    "    ys = torch.ones(1, num_samples).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(DEVICE).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        next_word = torch.multinomial(torch.nn.functional.softmax(prob, dim=-1), 1)\n",
    "        next_word = next_word.detach()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        next_word.view(1, -1)], dim=0)\n",
    "    return ys.transpose(0,1)\n",
    "\n",
    "def paraphrase(model, \n",
    "              srcs, \n",
    "              src_vocab, \n",
    "              tgt_vocab, \n",
    "              src_tokenizer, \n",
    "              decoder=greedy_decode, \n",
    "              ret_tokens=False, \n",
    "              ret_idx=False, \n",
    "              max_len_add=10,\n",
    "              input_idx=False,\n",
    "              **argv):\n",
    "    model.eval()\n",
    "    global_answers = []\n",
    "    for src in srcs:\n",
    "        if not input_idx:\n",
    "            tokens = [BOS_IDX] + [src_vocab.stoi[tok] for tok in src_tokenizer(src)]+ [EOS_IDX]\n",
    "            src = torch.LongTensor(tokens)\n",
    "        num_tokens = len(src)\n",
    "        src = src.reshape(num_tokens, 1)\n",
    "        \n",
    "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "        tgt_tokens = decoder(model, src, src_mask, max_len=num_tokens + max_len_add, start_symbol=BOS_IDX, **argv)\n",
    "\n",
    "        answers = []\n",
    "        for tgt_token in tgt_tokens:\n",
    "            if not ret_idx:\n",
    "                reference = []\n",
    "                for tok in tgt_token:\n",
    "                    if tok.item() == tgt_vocab['<eos>']:\n",
    "                        break\n",
    "                    if tok.item() not in {tgt_vocab['<eos>'], tgt_vocab['<bos>'], tgt_vocab['<pad>']}:\n",
    "                        reference.append(tgt_vocab.itos[tok])\n",
    "                answers.append(\" \".join(reference).strip())\n",
    "                if ret_tokens:\n",
    "                    answers[-1] = answers[-1].split(\" \")\n",
    "            else:\n",
    "                reference = []\n",
    "                for tok in tgt_token:\n",
    "                    if tok.item() == tgt_vocab['<eos>']:\n",
    "                        break\n",
    "                    if tok.item() not in {tgt_vocab['<eos>'], tgt_vocab['<bos>'], tgt_vocab['<pad>']}:\n",
    "                        reference.append(tok.item())\n",
    "                        \n",
    "                answers.append(reference)\n",
    "        global_answers.append(answers)\n",
    "    return global_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c65ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in (enumerate(valid_iter)):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                              src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca12359",
   "metadata": {},
   "source": [
    "## Базовое обучение без RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479ce4a",
   "metadata": {},
   "source": [
    "### Функции обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6557b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iter, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(train_iter):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, \n",
    "                       tgt_input, \n",
    "                       src_mask, \n",
    "                       tgt_mask,\n",
    "                       src_padding_mask, \n",
    "                       tgt_padding_mask, \n",
    "                       src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d4e8d",
   "metadata": {},
   "source": [
    "### Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35398491",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(vocab)\n",
    "TGT_VOCAB_SIZE = len(vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, \n",
    "                                 NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, \n",
    "                                 TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee07995",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b5af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.585, Val loss: 2.956, Epoch time = 46.839s, All time = 48.204s\n",
      "Epoch: 2, Train loss: 3.446, Val loss: 2.353, Epoch time = 47.250s, All time = 48.622s\n",
      "Epoch: 3, Train loss: 3.006, Val loss: 2.021, Epoch time = 47.126s, All time = 48.496s\n",
      "Epoch: 4, Train loss: 2.695, Val loss: 1.789, Epoch time = 47.338s, All time = 48.686s\n",
      "Epoch: 5, Train loss: 2.447, Val loss: 1.607, Epoch time = 47.526s, All time = 48.876s\n",
      "Epoch: 6, Train loss: 2.238, Val loss: 1.461, Epoch time = 47.660s, All time = 49.024s\n",
      "Epoch: 7, Train loss: 2.055, Val loss: 1.390, Epoch time = 47.774s, All time = 49.241s\n",
      "Epoch: 8, Train loss: 1.897, Val loss: 1.301, Epoch time = 47.755s, All time = 49.102s\n",
      "Epoch: 9, Train loss: 1.755, Val loss: 1.255, Epoch time = 47.286s, All time = 48.647s\n",
      "Epoch: 10, Train loss: 1.632, Val loss: 1.191, Epoch time = 47.471s, All time = 48.833s\n",
      "Epoch: 11, Train loss: 1.525, Val loss: 1.164, Epoch time = 47.395s, All time = 48.770s\n",
      "Epoch: 12, Train loss: 1.425, Val loss: 1.143, Epoch time = 47.532s, All time = 48.928s\n",
      "Epoch: 13, Train loss: 1.334, Val loss: 1.115, Epoch time = 47.441s, All time = 48.804s\n",
      "Epoch: 14, Train loss: 1.255, Val loss: 1.109, Epoch time = 47.308s, All time = 48.693s\n",
      "Epoch: 15, Train loss: 1.185, Val loss: 1.105, Epoch time = 47.057s, All time = 48.411s\n",
      "Epoch: 16, Train loss: 1.117, Val loss: 1.074, Epoch time = 47.538s, All time = 48.895s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(transformer, train_iter, optimizer, loss_fn)\n",
    "    end_time = time.time()\n",
    "    val_loss = evaluate(transformer, valid_iter)\n",
    "    all_time = time.time()\n",
    "    print(f\"Epoch: {epoch}, \"\n",
    "          f\"Train loss: {train_loss:.3f}, \"\n",
    "          f\"Val loss: {val_loss:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
    "          f\"All time = {(all_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a22bb",
   "metadata": {},
   "source": [
    "### Пример работы (greedy search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paraphrase(transformer, [\"in our work , we focus on supervised domain adaptation .\"], \n",
    "          vocab, \n",
    "          vocab, \n",
    "          tokenizer, \n",
    "          decoder=greedy_decode, num_samples=5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d130e0",
   "metadata": {},
   "source": [
    "### Пример работы (multinominal sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paraphrase(transformer, [\"in our work , we focus on supervised domain adaptation .\"], \n",
    "          vocab, \n",
    "          vocab, \n",
    "          tokenizer, \n",
    "          decoder=sampling_decode, num_samples=5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054660f6",
   "metadata": {},
   "source": [
    "## Обучение с RL\n",
    "Продолжаем обучение уже используя модель из предыдущего пункта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reward(object):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "        self.bert = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\").to(DEVICE)\n",
    "        self.bert.eval()\n",
    "        \n",
    "    def score(self, references, candidates):\n",
    "        assert len(references) == len(candidates)\n",
    "        with torch.no_grad():\n",
    "            tokes = reward.tokenizer(\n",
    "                references, return_tensors='pt', \n",
    "                padding=True, max_length=512, truncation=True).to(DEVICE)\n",
    "            ref_emb = reward.bert(**tokes)[1].cpu().numpy()\n",
    "            tokes = reward.tokenizer(\n",
    "                candidates, return_tensors='pt', \n",
    "                padding=True, max_length=512, truncation=True).to(DEVICE)\n",
    "            can_emb = reward.bert(**tokes)[1].cpu().numpy()\n",
    "\n",
    "        distances = 1-scipy.spatial.distance.cdist(can_emb, \n",
    "                                                   ref_emb,\n",
    "                                                   metric='cosine').diagonal()\n",
    "    \n",
    "        return distances.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = Reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_with_rl(model, train_iter, optimizer, loss_fn, alpha=0.75):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(train_iter):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, \n",
    "                       tgt_input, \n",
    "                       src_mask, \n",
    "                       tgt_mask,\n",
    "                       src_padding_mask, \n",
    "                       tgt_padding_mask, \n",
    "                       src_padding_mask)\n",
    "        \n",
    "######################RL-start##################################\n",
    "        logits_batch_first = logits.transpose(0,1)\n",
    "        # получаем предсказания для RL\n",
    "        toks = torch.multinomial(\n",
    "            torch.nn.functional.softmax(\n",
    "                logits_batch_first.reshape(-1, logits_batch_first.shape[-1]), \n",
    "                dim=-1), \n",
    "            1).reshape(logits_batch_first.shape[:2])\n",
    "\n",
    "\n",
    "        references = []\n",
    "        candidates = []\n",
    "        for real_toks, pred_toks in zip(tgt[1:,:].transpose(0,1), toks):\n",
    "            reference = []\n",
    "            for tok in real_toks:\n",
    "                if tok.item() == vocab['<eos>']:\n",
    "                    break\n",
    "                if tok.item() not in {vocab['<eos>'], vocab['<bos>'], vocab['<pad>']}:\n",
    "                    reference.append(vocab.itos[tok])\n",
    "            candidate = []\n",
    "            for tok in pred_toks:\n",
    "                if tok.item() == vocab['<eos>']:\n",
    "                    break\n",
    "                if tok.item() not in {vocab['<eos>'], vocab['<bos>'], vocab['<pad>']}:\n",
    "                    candidate.append(vocab.itos[tok])\n",
    "            references.append(' '.join(reference))\n",
    "            candidates.append(' '.join(candidate))\n",
    "\n",
    "        reward_tr = torch.tensor(reward.score(references, candidates)).float().to(DEVICE)\n",
    "\n",
    "        action_proba = torch.gather(torch.nn.functional.log_softmax(logits_batch_first, dim=-1), \n",
    "                                    2, \n",
    "                                    toks.view(*logits_batch_first.shape[:2], 1)).squeeze(-1)\n",
    "######################RL-end###################################\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = alpha*loss_fn(logits.reshape(-1, logits.shape[-1]), tgt[1:,:].reshape(-1)) \\\n",
    "               + (1-alpha)*(-1*reward_tr.view(-1,1)*action_proba).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch_with_rl(transformer, train_iter, optimizer, loss_fn)\n",
    "    end_time = time.time()\n",
    "    val_loss = evaluate(transformer, valid_iter)\n",
    "    all_time = time.time()\n",
    "    print(f\"Epoch: {epoch}, \"\n",
    "          f\"Train loss: {train_loss:.3f}, \"\n",
    "          f\"Val loss: {val_loss:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
    "          f\"All time = {(all_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fdbb2",
   "metadata": {},
   "source": [
    "### Пример работы (greedy search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af541e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paraphrase(transformer, [\"in our work , we focus on supervised domain adaptation .\"], \n",
    "          vocab, \n",
    "          vocab, \n",
    "          tokenizer, \n",
    "          decoder=greedy_decode, num_samples=5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe18637",
   "metadata": {},
   "source": [
    "### Пример работы (multinominal sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paraphrase(transformer, [\"in our work , we focus on supervised domain adaptation .\"], \n",
    "          vocab, \n",
    "          vocab, \n",
    "          tokenizer, \n",
    "          decoder=sampling_decode, num_samples=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b067b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
